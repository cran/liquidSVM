<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Installation</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>

<!-- MathJax scripts -->
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<p>To see a demonstration of the capabilities of liquidSVM from an R viewpoint,
please look at the <a href="demo.html">demo</a>.</p>

<blockquote>
<p><em>Disclaimer:</em> liquidSVM and the R-bindings are in general quite stable and well tested by several people.
However, use in production is at your own risk.</p>

<p>If you run into problems please check first the documentation for more details,
or report the bug to the maintainer.</p>
</blockquote>

<h1>Installation</h1>

<p>There are several options to install the package.</p>

<h2>Download and Install using R</h2>

<p>The most convenient way is to
use the standard install to get it from CRAN:</p>

<pre><code class="r">install.packages(&quot;liquidSVM&quot;)
</code></pre>

<p>You can also use our repository:</p>

<pre><code class="r">install.packages(&quot;liquidSVM&quot;, repos=&quot;http://www.isa.uni-stuttgart.de/software/R&quot;)
</code></pre>

<p>Remark that in R a package can be installed either as source
or binary</p>

<p>Source (default on Linux Systems): 
  : Allows for optimization to the system and liquidSVM can benefit a lot from these optimizations.
    The drawback is that this needs a C++ compiler. This is usually okay on Linux-systems,
    but on Windows one has to install <a href="https://cran.r-project.org/bin/windows/Rtools/">Rtools</a>,
    and on MacOS X <a href="https://itunes.apple.com/de/app/xcode/id497799835?mt=12">Xcode in MacApp Store</a>
    (<a href="https://developer.apple.com/download/">Xcode also for older MacOS versions</a>.)</p>

<p>Binary (default on Windows and MacOS X):
  : compiled versions are provided, so you do not need compilers.
    However, these are optimized for generic processors (e.g. they do not use AVX),
    and hence you might do much better on your machine if you compile it yourself.</p>

<p>You can change the default behaviour of <code>install.packages(...)</code>
under Windows/MacOS by using the parameter <code>type=&quot;source&quot;</code>.</p>

<blockquote>
<p>The binaries in our repository are only compiled using R version 3.*. If you use another
version, they might not work and you have to try source installation (<code>type=&quot;source&quot;</code>).</p>

<p>Note: on  MacOS X there can be an issue with binary package installation.
If you get the error <code>tar: Failed to set default locale</code> then consult</p>

<p><a href="https://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#Internationalization-of-the-R_002eapp">https://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#Internationalization-of-the-R_002eapp</a></p>
</blockquote>

<h2>Install a downloaded package</h2>

<p>Download the source or binary package from <a href="http://www.isa.uni-stuttgart.de/software/">http://www.isa.uni-stuttgart.de/software/</a>.
On the command line use:</p>

<pre><code>R CMD INSTALL path-to-package/liquidSVM_1.0.1.tar.gz
# Windows
Rcmd INSTALL path-to-package/liquidSVM_1.0.1.zip
# MacOS X using Termninal
R CMD INSTALL path-to-package/liquidSVM_1.0.1.tgz
</code></pre>

<p>or in a running R session:</p>

<pre><code class="r">install.packages(&quot;path-to-package/liquidSVM_1.0.1.tar.gz&quot;,repos=NULL)
# Windows binary
install.packages(&quot;path-to-package/liquidSVM_1.0.1.zip&quot;,repos=NULL)
# MacOS X binary
install.packages(&quot;path-to-package/liquidSVM_1.0.1.tgz&quot;,repos=NULL)
</code></pre>

<p>You can use also the means of any R-IDE.
E.g. in RStudio go to the menu</p>

<pre><code>Tools &gt; Install packages...
</code></pre>

<p>Then set <code>install from</code> to <code>package archive file (.tar.gz or .tgz)</code> and choose your package
and install the package.</p>

<h2>Advanced Configuration Options with Source Install</h2>

<p>liquidSVM can be configured for different uses of available hardware.
We provide the following configurations:</p>

<p><code>native</code>
  : compiles for the current system, e.g. uses AVX or even AVX2 if available. This uses <code>g++/clang++ -march=native -O3</code>.</p>

<p><code>generic</code>
  : compiles for a wide range of currently deployed CPUs (uses SSE). This uses <code>g++/clang++ -mtune=generic -O3</code>.
    Our binary packages are compiled with this configuration.</p>

<p><code>default</code>
  : compiles using the default values provided by R.</p>

<p><code>debug</code>
  : compiles with debugging enabled.</p>

<p><code>empty</code>
  : gives no default compile arguments.</p>

<p>Additional compiler flags can be provided as well. On the command line,
here are some examples:</p>

<pre><code>R CMD INSTALL --configure-args=native path-to-package/liquidSVM_1.0.1.tar.gz
R CMD INSTALL --configure-args=generic path-to-package/liquidSVM_1.0.1.tar.gz
R CMD INSTALL --configure-args=&quot;empty -march=core2 -O3&quot; path-to-package/liquidSVM_1.0.1.tar.gz
</code></pre>

<p>or in a running R session:</p>

<pre><code class="r">install.packages(&quot;liquidSVM&quot;,configure.args=&quot;native&quot;)
install.packages(&quot;liquidSVM&quot;,configure.args=&quot;generic&quot;)
install.packages(&quot;liquidSVM&quot;,configure.args=&quot;empty -march=core2 -O3&quot;)
</code></pre>

<p>Under MacOS you have to add the paramter <code>type=&quot;source&quot;</code> in order to trigger compilation.</p>

<blockquote>
<p><strong>Hint:</strong> to see whether liquidSVM got compiled with SSE and/or AVX use:</p>

<pre><code class="r">compilationInfo()
#&gt; [1] &quot;Compiled without vectorization&quot;
</code></pre>
</blockquote>

<h3>Windows configuration</h3>

<p>On <strong>Windows</strong> unfortunately neither <code>--configure-args</code> nor <code>configure.args</code> have any effect.
We enable compilation configuration by reading the environment variable <code>LIQUIDSVM_CONFIGURE_ARGS</code>
and using it in the same way as the configure args on the other platforms (see above).
So on the Windows command line use</p>

<pre><code>set LIQUIDSVM_CONFIGURE_ARGS=native
R CMD INSTALL path-to-package/liquidSVM_1.0.1.tar.gz

set LIQUIDSVM_CONFIGURE_ARGS=empty -march=core2 -O3
R CMD INSTALL path-to-package/liquidSVM_1.0.1.tar.gz
</code></pre>

<p>Remark that no quotation has to be used.
It is not tested whether paths with spaces will work in this setting.</p>

<p>If you wish to install from within R you can specify the environment variable as well:</p>

<pre><code class="r">Sys.setenv(LIQUIDSVM_CONFIGURE_ARGS=&quot;native&quot;)
install.packages(&quot;liquidSVM&quot;)

Sys.setenv(LIQUIDSVM_CONFIGURE_ARGS=&quot;empty -march=core2 -O3&quot;)
install.packages(&quot;liquidSVM&quot;)
</code></pre>

<p>If you have <a href="https://cran.r-project.org/bin/windows/Rtools/">Rtools</a> installed then
you should definitely try to use <code>native</code>, because on Windows we use <code>generic</code> as the default configuration even for source installs.</p>

<h3>Common Problems</h3>

<ul>
<li><strong>MacOS X</strong>: It seems that in some cases <code>clang++ -march=native</code> does not activate AVX even if it is available.
Hence if you know it is available, use <code>configure.args=&quot;native -mavx&quot;</code> or even <code>configure.args=&quot;native -mavx2&quot;</code>.</li>
<li><strong>Windows</strong>: On one machine <code>set LIQUIDSVM_CONFIGURE_ARGS=native</code> compiled but crashed on
execution: the compiler thought that FusedMultiplyAdd was available but it was not.
The solution was to <code>set LIQUIDSVM_CONFIGURE_ARGS=native -mno-fma</code></li>
</ul>

<p>For GCC it can help to use <code>g++ -Q --help=target -march=native ...</code> to figure out which options
trigger what optimizations. For both GCC and clang you can also print the compilation headers by
<code>g++ -march=native ... -dM -E - &lt; /dev/null | egrep &quot;SSE|AVX&quot;</code>.</p>

<h2>CUDA</h2>

<p>liquidSVM also is able to calculate the kernel on a GPU if it is compiled with CUDA-support.
Since there is a  big overhead in moving the kernel matrix from the GPU memory,
this is most useful for problems with many feature-dimensions (see <a href="demo.html#CUDA">demo</a>)</p>

<p>To activate CUDA support you have to specify its location (usually <code>/usr/local/cuda</code>)
as a parameter to the configure arguments:</p>

<pre><code>R CMD INSTALL --configure-args=&quot;native /my/path/to/cuda&quot; path-to-package/liquidSVM_1.0.1.tar.gz
</code></pre>

<p>or again in R</p>

<pre><code class="r">install.packages(&#39;liquidSVM&#39;,configure.args=&quot;native /my/path/to/cuda&quot;)
</code></pre>

<blockquote>
<p>Note that due to lack of testing machines this is known to work only on some Linux machines.
The above instructions will probably not work on Windows!</p>
</blockquote>

<p>If you have compiled with CUDA-support, you can activate it for a computation by using <code>svm(..., GPUs=1)</code>:</p>

<h1>Configuration parameters</h1>

<p>The uses of <code>svm(...)</code>, <code>lsSVM(...)</code>, <code>mcSVM(...)</code>, etc. can be configured
using the following parameters.</p>

<h2>Overview of Configuration Parameters</h2>

<p><code>display</code>
  : This parameter determines the amount of output of
    you see at the screen: The larger its value is,
    the more you see. This can help as a progress indication.</p>

<p><code>scale</code>
  : If set to a true value then for every feature in the training data
    a scaling is calculated so that its values lie in the interval \([0,1]\).
    The training then is performed using these scaled values
    and any testing data is scaled transparently as well.</p>

<pre><code>Because SVMs are not scale-invariant any data should be scaled
for two main reasons: First that all features have the same weight,
and second to assure that the default gamma parameters that liquidSVM
provide remain meaningful.

If you do not have scaled the data previously this is an easy option.
</code></pre>

<p><code>threads</code>
  : This parameter determines the number of cores
    used for computing the kernel matrices, the
    validation error, and the test error.</p>

<pre><code>* `threads=0` (default) means that all physical cores of your CPU run one thread. 
* `threads=-1` means that all but one physical cores of your CPU run one thread.
</code></pre>

<p><code>partition_choice</code>
:   This parameter determines the way the input space
    is partitioned. This allows larger data sets for which
    the kernel matrix does not fit into memory.</p>

<pre><code>* `partition_choice=0` (default) disables partitioning.
* `partition_choice=6` gives usually highest speed.
* `partition_choice=5` gives usually the best test error.
</code></pre>

<p><code>grid_choice</code>
:   This parameter determines the size of the hyper-
    parameter grid used during the training phase.
    Larger values correspond to larger grids. By
    default, a 10x10 grid is used. Exact descriptions are given in the next section.</p>

<p><code>adaptivity_control</code>
:   This parameter determines, whether an adaptive
    grid search heuristic is employed. Larger values
    lead to more aggressive strategies. The default
    <code>adaptivity_control = 0</code> disables the heuristic.</p>

<p><code>random_seed</code>
:   This parameter determines the seed for the random
    generator. <code>random_seed</code> = -1 uses the internal
    timer create the seed. All other values lead to
    repeatable behavior of the svm.</p>

<p><code>folds</code>
  : How many folds should be used.</p>

<h2>Specialized configuration parameters</h2>

<p>Parameters for regression (least-squares, quantile, and expectile)</p>

<p><code>clipping</code>
  : This parameter determines whether the decision
    functions should be clipped at the specified
    value. The value <code>clipping</code> = -1.0 leads to
    an adaptive clipping value, whereas <code>clipping</code> = 0
    disables clipping.</p>

<p>Parameter for multiclass classification determine the multiclass strategy:
<code>mc-type=0</code>
  : AvA with hinge loss.
<code>mc-type=1</code>
  : OvA with least squares loss.
<code>mc-type=2</code>
  : OvA with hinge loss.
<code>mc-type=3</code>
  : AvA with least squares loss.</p>

<p>Parameters for Neyman-Pearson Learning</p>

<p><code>class</code>
  : The class, the <code>constraint</code> is enforced on.</p>

<p><code>constraint</code>
  : The constraint on the false alarm rate. The script
    actually considers a couple of values around the
    value of <code>constraint</code> to give the user an informed
    choice.</p>

<h2>Hyperparameter Grid</h2>

<p>For Support Vector Machines two hyperparameters need to be determined:</p>

<ul>
<li><code>gamma</code> the bandwith of the kernel </li>
<li><code>lambda</code> has to be chosen such that neither over- nor underfitting happen.
lambda values are the classical regularization parameter in front of the norm term.</li>
</ul>

<p>liquidSVM has a built-in a cross-validation scheme to calculate validation errors for
many values of these hyperparameters and then to choose the best pair.
Since there are two parameters this means we consider a two-dimensional grid.</p>

<p>For both parameters either specific values can be given or a geometrically spaced grid can be specified.</p>

<p><code>gamma_steps</code>, <code>min_gamma</code>, <code>max_gamma</code>
  : specifies in the interval between <code>min_gamma</code> and <code>max_gamma</code> there should be <code>gamma_steps</code> many values</p>

<p><code>gammas</code>
  : e.g. <code>gammas=c(0.1,1,10,100)</code> will do these four gamma values</p>

<p><code>lambda_steps</code>, <code>min_lambda</code>, <code>max_lambda</code>
  : specifies in the interval between <code>min_lambda</code> and <code>max_lambda</code> there should be <code>lambda_steps</code> many values</p>

<p><code>lambdas</code>
  : e.g. <code>lambdas=c(0.1,1,10,100)</code> will do these four lambda values</p>

<p><code>c_values</code>
  : the classical term in front of the empirical error term,
    e.g. <code>c_values=c(0.1,1,10,100)</code> will do these four cost values (basically inverse of <code>lambdas</code>)</p>

<p>Note the min and max values are 
scaled according the the number of samples, the dimensionality
of the data sets, the number of folds used, and the estimated 
diameter of the data set.</p>

<p>Using <code>grid_choice</code> allows for some general choices of these parameters</p>

<table><thead>
<tr>
<th><code>grid_choice</code></th>
<th>0</th>
<th>1</th>
<th>2</th>
</tr>
</thead><tbody>
<tr>
<td><code>gamma_steps</code></td>
<td>10</td>
<td>15</td>
<td>20</td>
</tr>
<tr>
<td><code>lambda_steps</code></td>
<td>10</td>
<td>15</td>
<td>20</td>
</tr>
<tr>
<td><code>min_gamma</code></td>
<td>0.2</td>
<td>0.1</td>
<td>0.05</td>
</tr>
<tr>
<td><code>max_gamma</code></td>
<td>5.0</td>
<td>10.0</td>
<td>20.0</td>
</tr>
<tr>
<td><code>min_lambda</code></td>
<td>0.001</td>
<td>0.0001</td>
<td>0.00001</td>
</tr>
<tr>
<td><code>max_lambda</code></td>
<td>0.01</td>
<td>0.01</td>
<td>0.01</td>
</tr>
</tbody></table>

<p>Using negative values of <code>grid_choice</code> we create a grid with listed gamma and lambda values:</p>

<table><thead>
<tr>
<th><code>grid_choice</code></th>
<th>-1</th>
</tr>
</thead><tbody>
<tr>
<td><code>gammas</code></td>
<td><code>c(10.0, 5.0, 2.0, 1.0, 0.5, 0.25, 0.1, 0.05)</code></td>
</tr>
<tr>
<td><code>lambdas</code></td>
<td><code>c(1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001)</code></td>
</tr>
</tbody></table>

<table><thead>
<tr>
<th><code>grid_choice</code></th>
<th>-2</th>
</tr>
</thead><tbody>
<tr>
<td><code>gammas</code></td>
<td><code>c(10.0, 5.0, 2.0, 1.0, 0.5, 0.25, 0.1, 0.05)</code></td>
</tr>
<tr>
<td><code>c_values</code></td>
<td><code>c(0.01, 0.1, 1, 10, 100, 1000, 10000)</code></td>
</tr>
</tbody></table>

<h2>Adaptive Grid</h2>

<p>An adaptive grid search can be activated. The higher the values
of <code>MAX_LAMBDA_INCREASES</code> and <code>MAX_NUMBER_OF_WORSE_GAMMAS</code> are set
the more conservative the search strategy is. The values can be 
freely modified.</p>

<table><thead>
<tr>
<th><code>ADAPTIVITY_CONTROL</code></th>
<th>1</th>
<th>2</th>
</tr>
</thead><tbody>
<tr>
<td><code>MAX_LAMBDA_INCREASES</code></td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td><code>MAX_NUMBER_OF_WORSE_GAMMAS</code></td>
<td>4</td>
<td>3</td>
</tr>
</tbody></table>

<h2>Cells</h2>

<p>A major issue with SVMs is that for larger sample sizes the kernel matrix
does not fit into the memory any more.
Classically this gives an upper limit for the class of problems that traditional
SVMs can handle without significant runtime increase.
Furthermore also the time complexity is at least \(O(n^2)\).</p>

<p>liquidSVM implements two major concepts to circumvent these issues.
One is random chunks which is known well in the literature.
However we prefer the new alternative of splitting the space into
spatial cells and use local SVMs on every cell.</p>

<p>If you specify <code>useCells=TRUE</code> then the sample space \(X\) gets partitioned into
a number of cells.
The training is done first for cell 1 then for cell 2 and so on.
Now, to predict the label for a value \(x\in X\) liquidSVM first finds out
to which cell this \(x\) belongs and then uses the SVM of that cell to predict
a label for it.</p>

<blockquote>
<p>If you run into memory issues turn cells on: <code>useCells=TRUE</code></p>
</blockquote>

<p>This is quite performant, since the complexity in both
time and memore are both \(O(\mbox{CELLSIZE} \times n)\)
and this holds both for training as well as testing!
It also can be shown that the quality of the solution is comparable,
at least for moderate dimensions.</p>

<p>The cells can be configured using the <code>partition_choice</code>:</p>

<p>1) This gives a partition into random
    chunks of size 2000</p>

<pre><code>`VORONOI=c(1, 2000)`
</code></pre>

<p>2)  This gives a partition into 10
    random chunks</p>

<pre><code>`VORONOI=c(2, 10)`
</code></pre>

<p>3)  This gives a Voronoi partition into cells with radius 
    not larger than 1.0. For its creation a subsample containing
    at most 50.000 samples is used. </p>

<pre><code>  `VORONOI=c(3, 1.0, 50000)`
</code></pre>

<p>4)  This gives a Voronoi partition into cells with at most 2000 
    samples (approximately). For its creation a subsample containing
    at most 50.000 samples is used. A shrinking heuristic is used 
    to reduce the number of cells.</p>

<pre><code>  `VORONOI=c(4, 2000, 1, 50000)`
</code></pre>

<p>5)  This gives a overlapping regions with at most 2000 samples
    (approximately). For its creation a subsample containing
    at most 50.000 samples is used. A stopping heuristic is used 
    to stop the creation of regions if 0.5 * 2000 samples have
    not been assigned to a region, yet. </p>

<pre><code>`VORONOI=c(5, 2000, 0.5, 50000, 1)`
</code></pre>

<p>6)  This splits the working sets into Voronoi like with <code>PARTITION_TYPE=4</code>.
    Unlike that case, the centers for the Voronoi partition are
    found by a recursive tree approach, which in many cases may be
    faster.</p>

<pre><code> `VORONOI=c(6, 2000, 1, 50000, 2.0, 20, 4,)`
</code></pre>

<p>The first parameter values correspond to <code>NO_PARTITION</code>, <code>RANDOM_CHUNK_BY_SIZE</code>, <code>RANDOM_CHUNK_BY_NUMBER</code>, <code>VORONOI_BY_RADIUS</code>, <code>VORONOI_BY_SIZE</code>, <code>OVERLAP_BY_SIZE</code></p>

<h2>Weights</h2>

<ul>
<li><p>qt, ex:
Here the number of considered tau-quantiles/expectiles as well as the 
considered tau-values are defined. You can freely change these
values but notice that the list of tau-values is space-separated!</p></li>
<li><p>npl, roc:
Here, you define, which weighted classification problems will be considered.
The choice is usually a bit tricky. Good luck &hellip;</p></li>
</ul>

<pre><code class="r">NPL:
WEIGHT_STEPS=10
MIN_WEIGHT=0.001
MAX_WEIGHT=0.5
GEO_WEIGHTS=1

ROC:
WEIGHT_STEPS=9
MAX_WEIGHT=0.9
MIN_WEIGHT=0.1
GEO_WEIGHTS=0
</code></pre>

<h2>Grouped Cross Validation</h2>

<p>By specifying <code>groupIds</code> when initializing an SVM samples obtain group ids.
This by default also sets <code>FOLDS_KIND</code> to <code>GROUPED</code>.
If the latter is the case then samples with the same group id will be put
into the same fold at cross validation.
This is important if e.g. there are several patients with several measurements each.</p>

<h2>More Advanced Parameters</h2>

<p>The following parameters should only employed by experienced users and are self-explanatory for these:</p>

<p><code>KERNEL</code>
  : specifies the kernel to use, at the moment either <code>GAUSS_RBF</code> or <code>POISSON</code></p>

<p><code>RETRAIN_METHOD</code>
  : After training on grids and folds there are only solutions on folds.
    In order to construct a global solution one can either retrain on the whole
    training data (<code>SELECT_ON_ENTIRE_TRAIN_SET</code>) or
    the (partial) solutions from the training are
    kept and combined using voting (<code>SELECT_ON_EACH_FOLD</code> default)</p>

<p><code>store_solutions_internally</code>
  : If this is true (default in all applicable cases) then the solutions of the train phase
    are stored and can be just reused in the select phase.
    If you slowly run out of memory during the train phase maybe disable this.
    However then in the select phase the best models have to be trained again.</p>

<p>For completeness here are some values that usually get set by the learning scenario</p>

<p><code>SVM_TYPE</code>
  : <code>KERNEL_RULE</code>, <code>SVM_LS_2D</code>, <code>SVM_HINGE_2D</code>, <code>SVM_QUANTILE</code>, <code>SVM_EXPECTILE_2D</code>, <code>SVM_TEMPLATE</code></p>

<p><code>LOSS_TYPE</code>
  : <code>CLASSIFICATION_LOSS</code>, <code>MULTI_CLASS_LOSS</code>, <code>LEAST_SQUARES_LOSS</code>, <code>WEIGHTED_LEAST_SQUARES_LOSS</code>, <code>PINBALL_LOSS</code>, <code>TEMPLATE_LOSS</code></p>

<p><code>VOTE_SCENARIO</code>
  : <code>VOTE_CLASSIFICATION</code>, <code>VOTE_REGRESSION</code>, <code>VOTE_NPL</code></p>

<p><code>KERNEL_MEMORY_MODEL</code>
  : <code>LINE_BY_LINE</code>, <code>BLOCK</code>, <code>CACHE</code>, <code>EMPTY</code></p>

<p><code>FOLDS_KIND</code>
  : <code>BLOCKS</code>, <code>ALTERNATING</code>, <code>RANDOM</code>, <code>STRATIFIED</code>, <code>GROUPED</code>, <code>RANDOM_SUBSET</code></p>

<p><code>WS_TYPE</code>
  : <code>FULL_SET</code>, <code>MULTI_CLASS_ALL_VS_ALL</code>, <code>MULTI_CLASS_ONE_VS_ALL</code>, <code>BOOT_STRAP</code></p>

<h1>Known Issues / Common Problems</h1>

<ul>
<li><p>Ctrl-C / Interrupt is tricky. It works most of the time, but it can fail.
If you get weird results or errors save your models and restart the R session.</p></li>
<li><p>CUDA has not been tested neither on Windows nor on macOS.</p></li>
<li><p>32-bit has been seen to work but is not supported.</p></li>
</ul>

<h2>Using external parallelization</h2>

<p>liquidSVM does its own threading - hence do not parallelize on top of that, unless
you know what you are doing. Hence just give the parameter <code>threads=n</code> or let
the default use all of your physical cores.</p>

<p>If you really want to do it yourself you have to serialze the solutions.
Furthermore you have to be carefule to assign disjoint cores
else they will fight for the same core:</p>

<pre><code class="r">library(parallel)
## how big should the cluster be
workers &lt;- 2
cl &lt;- makeCluster(workers)
## how many threads should each worker use
threads &lt;- 2

sml &lt;- liquidData(&#39;reg-1d&#39;)
clusterExport(cl, c(&quot;sml&quot;,&quot;threads&quot;,&quot;workers&quot;))
obj &lt;- parLapply(cl, 1:workers, function(i) {
  library(liquidSVM)
  ## to make it interesting use disjoint parts of sml$train
  data &lt;- sml$train[ seq(i,nrow(sml$train),workers) , ]
  ## the second argument to threads sets the offset of cores
  model &lt;- lsSVM(Y~., data, threads=c(threads,threads*(i-1)) )
  ## finally return the serialized solution
  serialize.liquidSVM(model)
})
for(i in 1:workers){
  ## get the solution in the master session
  model &lt;- unserialize.liquidSVM(obj[[i]])
  print(errors(test(model,sml$test)))
}
#&gt; val_error
#&gt;   0.00542
#&gt;  val_error
#&gt;   0.00583
</code></pre>

</body>

</html>
